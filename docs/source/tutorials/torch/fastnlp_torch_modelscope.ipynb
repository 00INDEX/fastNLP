{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 使用 ModelScope 和 fastNLP 来实现情感分类\n",
    "\n",
    "&emsp;&emsp;本篇教程将为您详细展示如何使用 `fastNLP` 和 `ModelScope` 来实现简单的情感任务。\n",
    "\n",
    "&emsp;&emsp;本篇教程的数据集是SST-2 文本情感二分类数据集。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. 基础介绍：达摩院 ModelScope 和 StructBERT 模型\n",
    "\n",
    "### ModelScope\n",
    "\n",
    "&emsp;&emsp;**ModelScope** 旨在打造下一代开源的模型即服务共享平台，为泛AI开发者提供灵活、易用、低成本的一站式模型服务产品，让模型应用更简单。提供的服务包括\n",
    "\n",
    "- **丰富的预训练SOTA模型**\n",
    "- **多元开放的数据集**\n",
    "- **一行代码使用模型推理能力**\n",
    "- **十行代码快速构建专属行业模型**\n",
    "- **即开即用的在线开发平台**\n",
    "- **灵活的模型框架与部署方式**\n",
    "- **丰富的教学内容与技术资源**\n",
    "\n",
    "### StructBERT\n",
    "\n",
    "&emsp;&emsp;StructBERT 的中文 Large 预训练模型是使用 wikipedia 数据和 masked language model 任务训练的中文自然语言理解预训练模型。我们通过引入语言结构信息的方式，将 BERT 扩展为了一个新模型 --StructBERT。我们在 BERT 的基础上新引入了两个辅助任务来让模型学习字级别的顺序信息和句子级别的顺序信息， 从而更好的建模语言结构。\n",
    "\n",
    "![模型结构](https://www.modelscope.cn/api/v1/models/damo/nlp_structbert_sentiment-classification_chinese-base/repo?Revision=master&FilePath=model.jpg&View=true)\n",
    "\n",
    "&emsp;&emsp;详见论文 [StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding](https://arxiv.org/abs/1908.04577)。\n",
    "\n",
    "\n",
    "## 2. 准备工作：加载数据，加载 tokenizer、预处理 dataset、dataloader\n",
    "\n",
    "&emsp;&emsp;在此教程中，我们仍旧使用 `sst-2` 来训练模型，实现情感分类。首先使用 `datasets` 来加载 `sst-2`，通过 `fastNLP` 的 `DataSet` 和 `DataBundle` 改变数据集的格式。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/remote-home/kychen/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe805dbcd434c7bbad07b563e87f701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total 3 datasets:\n",
      "\ttrain has 10000 instances.\n",
      "\tval has 872 instances.\n",
      "\ttest has 1000 instances.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fastNLP.io import DataBundle\n",
    "from fastNLP import DataSet\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = load_dataset(\"glue\", \"sst2\", split=[\"train\", \"validation\", \"test\"])\n",
    "train_dataset, val_dataset, test_dataset = train_dataset[:], val_dataset[:], test_dataset[:]\n",
    "\n",
    "train_dataset = DataSet(train_dataset)\n",
    "val_dataset = DataSet(val_dataset)\n",
    "test_dataset = DataSet(test_dataset)\n",
    "\n",
    "datasets = {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset}\n",
    "data_bundle = DataBundle(datasets=datasets)\n",
    "print(data_bundle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "&emsp;&emsp;之后，通过 `snapshot_download` 函数将预训练模型下载到本地，使用 `SequenceClassificationPreprocessor` 将句子进行分词，并提取特征。\n",
    "\n",
    "&emsp;&emsp;其中，`SequenceClassificationPreprocessor` 预处理器基于 `transformers.tokenizer` 实现，用于各输入格式符合 `transformers` 输入格式的文本分类预处理。在传入数据后，预处理器会尝试将字符串类型、int类型的标签映射为 id，float 类型的 id 会保持不变。\n",
    "\n",
    "&emsp;&emsp;采用`cache_results`，可以缓存处理的数据，节省非首次处理数据的时间\n",
    "\n",
    "&emsp;&emsp;同时，我们通过分词，提取出特征，并将这些特征加入`data_bundle`数据集中，特征包括\n",
    "\n",
    "- `input_ids`\n",
    "- `attention_mask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 16:59:08,521 - modelscope - INFO - PyTorch version 1.13.0 Found.\n",
      "2022-11-10 16:59:08,524 - modelscope - INFO - Loading ast index from /remote-home/kychen/.cache/modelscope/ast_indexer\n",
      "2022-11-10 16:59:08,616 - modelscope - INFO - Loading done! Current index file version is 1.0.3, with md5 f03e7e04ee360a0482e2f177143f01c2\n",
      "2022-11-10 16:59:09,632 - modelscope - INFO - Model revision not specified, use the latest revision: v1.0.0\n",
      "2022-11-10 16:59:09,864 - modelscope - INFO - File config.json already in cache, skip downloading!\n",
      "2022-11-10 16:59:09,866 - modelscope - INFO - File configuration.json already in cache, skip downloading!\n",
      "2022-11-10 16:59:09,867 - modelscope - INFO - File label_mapping.json already in cache, skip downloading!\n",
      "2022-11-10 16:59:09,868 - modelscope - INFO - File model.jpg already in cache, skip downloading!\n",
      "2022-11-10 16:59:09,870 - modelscope - INFO - File pytorch_model.bin already in cache, skip downloading!\n",
      "2022-11-10 16:59:09,870 - modelscope - INFO - File README.md already in cache, skip downloading!\n",
      "2022-11-10 16:59:09,871 - modelscope - INFO - File vocab.txt already in cache, skip downloading!\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'SbertTokenizer'.\n",
      "2022-11-10 16:59:10,141 - modelscope - INFO - The key of sentence1: sentence1, The key of sentence2: None, The key of label: label\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d2da471edb4ee98064b869694b56dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204f4c39b98e44cbb9c189ee8fab55d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b519dc5492cc423a9346bb0055a46402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[17:00:26] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Save cache to                                        <a href=\"file:///remote-home/kychen/anaconda3/envs/pytorch/lib/python3.8/site-packages/fastNLP/core/utils/cache_results.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cache_results.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/kychen/anaconda3/envs/pytorch/lib/python3.8/site-packages/fastNLP/core/utils/cache_results.py#343\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">343</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/remote-home/kychen/caches/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">5be5bd1c_cache.pkl.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[17:00:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Save cache to                                        \u001b]8;id=638704;file:///remote-home/kychen/anaconda3/envs/pytorch/lib/python3.8/site-packages/fastNLP/core/utils/cache_results.py\u001b\\\u001b[2mcache_results.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=177998;file:///remote-home/kychen/anaconda3/envs/pytorch/lib/python3.8/site-packages/fastNLP/core/utils/cache_results.py#343\u001b\\\u001b[2m343\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35m/remote-home/kychen/caches/\u001b[0m\u001b[95m5be5bd1c_cache.pkl.\u001b[0m       \u001b[2m                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "from modelscope.preprocessors import SequenceClassificationPreprocessor\n",
    "from fastNLP import cache_results\n",
    "\n",
    "\n",
    "@cache_results('caches/cache.pkl')\n",
    "def process_data(data_bundle, model_name):\n",
    "    tokenizer = SequenceClassificationPreprocessor.from_pretrained(model_name)\n",
    "\n",
    "    def _process(review):\n",
    "        encodings_review = tokenizer(review)\n",
    "\n",
    "        input_ids = encodings_review[\"input_ids\"].squeeze()\n",
    "\n",
    "        attention_mask = encodings_review[\"attention_mask\"].squeeze()\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "    data_bundle.apply_field_more(_process, field_name='sentence')\n",
    "\n",
    "    return data_bundle, tokenizer\n",
    "\n",
    "\n",
    "model_id = 'damo/nlp_structbert_sentiment-classification_chinese-base'\n",
    "model_checkpoint = snapshot_download(model_id)\n",
    "\n",
    "data_bundle, tokenizer = process_data(data_bundle, model_checkpoint, _refresh=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "&emsp;&emsp;再然后，**定义校对函数 collate_fn 对齐同个 batch 内的每笔数据**，需要注意的是该函数的 **返回值必须是字典**，**键值必须同待训练模型的 `train_step` 和 `evaluate_step` 函数的参数相对应**；这也就是在基础篇 [tutorial-0](../basic/fastnlp_tutorial_0.ipynb) 中便被强调的，`fastNLP v1.0`的第一条**参数匹配**机制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([tensor([[  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        [  101,   163,  8171,  ...,     0,     0,     0],\n",
      "        [  101,  8513,  9024,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8997,  8859,  ...,     0,     0,     0],\n",
      "        [  101, 12311,  8329,  ...,     0,     0,     0],\n",
      "        [  101,   143,  8373,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1])])\n",
      "dict_values([tensor([[  101,  8174, 13152,  ...,     0,     0,     0],\n",
      "        [  101, 10677, 11582,  ...,     0,     0,     0],\n",
      "        [  101,   119,   119,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   151, 11643,  ...,     0,     0,     0],\n",
      "        [  101, 13158,  9457,  ...,     0,     0,     0],\n",
      "        [  101,   119,   119,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0])])\n",
      "dict_values([tensor([[  101,   143,  8373,  ...,     0,     0,     0],\n",
      "        [  101,  8898,  8174,  ...,     0,     0,     0],\n",
      "        [  101,  8233,  8895,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8233, 10038,  ...,     0,     0,     0],\n",
      "        [  101,   143,   161,  ...,     0,     0,     0],\n",
      "        [  101,   143, 11541,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1])])\n",
      "dict_values([tensor([[  101, 11325,   143,  ...,     0,     0,     0],\n",
      "        [  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        [  101,  8233, 11297,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11515,  8778,  ...,     0,     0,     0],\n",
      "        [  101,  8174,  9470,  ...,     0,     0,     0],\n",
      "        [  101,  8281,  8554,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1])])\n",
      "dict_values([tensor([[  101,  8174, 10860,  ...,     0,     0,     0],\n",
      "        [  101,  8357,   165,  ...,     0,     0,     0],\n",
      "        [  101,  8898,  8357,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8174,  8968,  ...,     0,     0,     0],\n",
      "        [  101, 11136,  8310,  ...,     0,     0,     0],\n",
      "        [  101,  8554,  8310,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0])])\n",
      "dict_values([tensor([[  101,  8174,  8647,  ...,     0,     0,     0],\n",
      "        [  101,  9631, 10551,  ...,     0,     0,     0],\n",
      "        [  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8898, 12174,  ...,     0,     0,     0],\n",
      "        [  101,  8120,  8871,  ...,     0,     0,     0],\n",
      "        [  101,  8554,   160,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0])])\n",
      "dict_values([tensor([[  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        [  101,  8275,  8968,  ...,     0,     0,     0],\n",
      "        [  101,  8281,  8174,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        [  101, 11515,  9132,  ...,     0,     0,     0],\n",
      "        [  101, 11136,  8310,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0])])\n",
      "dict_values([tensor([[  101,  8913, 11208,  ...,     0,     0,     0],\n",
      "        [  101,  8554, 11099,  ...,     0,     0,     0],\n",
      "        [  101,  8233, 11643,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   143, 11099,  ...,     0,     0,     0],\n",
      "        [  101, 11485, 12240,  ...,     0,     0,     0],\n",
      "        [  101,  8217,  8174,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])])\n",
      "dict_values([tensor([[  101,  8556,  9007,  ...,     0,     0,     0],\n",
      "        [  101,  8233,  8376,  ...,     0,     0,     0],\n",
      "        [  101, 11541,  9049,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8174,  9537,  ...,     0,     0,     0],\n",
      "        [  101,  9100,  8815,  ...,     0,     0,     0],\n",
      "        [  101,   143,  8968,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1])])\n",
      "dict_values([tensor([[  101,   165,  8963,  ...,     0,     0,     0],\n",
      "        [  101,  8174,  9186,  ...,     0,     0,     0],\n",
      "        [  101,  9053,   143,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8233, 10985,  ...,     0,     0,     0],\n",
      "        [  101,  8120,  9018,  ...,     0,     0,     0],\n",
      "        [  101,  8993, 11901,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1])])\n",
      "dict_values([tensor([[  101,   163, 10507,  ...,     0,     0,     0],\n",
      "        [  101,  9059,  9577,  ...,     0,     0,     0],\n",
      "        [  101, 11136, 10235,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8363,  8457,  ...,     0,     0,     0],\n",
      "        [  101,  8898,  8357,  ...,     0,     0,     0],\n",
      "        [  101, 10353, 10073,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1])])\n",
      "dict_values([tensor([[  101, 10843,  8857,  ...,     0,     0,     0],\n",
      "        [  101,  8895,  8333,  ...,     0,     0,     0],\n",
      "        [  101,  8233, 10123,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 12894, 10076,  ...,     0,     0,     0],\n",
      "        [  101,   162,  8449,  ...,     0,     0,     0],\n",
      "        [  101,  8174, 11099,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1])])\n",
      "dict_values([tensor([[  101,   143, 10399,  ...,     0,     0,     0],\n",
      "        [  101, 11303,  8716,  ...,     0,     0,     0],\n",
      "        [  101, 12323,  8299,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 12289, 11139,  ...,     0,     0,     0],\n",
      "        [  101,  9064,  9143,  ...,     0,     0,     0],\n",
      "        [  101,  9353,   117,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1])])\n",
      "dict_values([tensor([[  101,  8256,  8174,  ...,     0,     0,     0],\n",
      "        [  101,  8554,  8310,  ...,     0,     0,     0],\n",
      "        [  101,  9059, 10110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8422,  8847,  ...,     0,     0,     0],\n",
      "        [  101,   143,  8362,  ...,     0,     0,     0],\n",
      "        [  101,  8792,  9256,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1])])\n",
      "dict_values([tensor([[  101,  9059, 10716,  ...,     0,     0,     0],\n",
      "        [  101, 12289,  8180,  ...,     0,     0,     0],\n",
      "        [  101,  8205, 12654,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   143,  8120,  ...,     0,     0,     0],\n",
      "        [  101,  9064,   157,  ...,     0,     0,     0],\n",
      "        [  101,  8575,  9868,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1])])\n",
      "dict_values([tensor([[  101, 11081,  9664,  ...,     0,     0,     0],\n",
      "        [  101,  8233,  8172,  ...,     0,     0,     0],\n",
      "        [  101,  8233,  8513,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8898,  8357,  ...,     0,     0,     0],\n",
      "        [  101,  8243,  8299,  ...,     0,     0,     0],\n",
      "        [  101,  8275,  8429,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0])])\n",
      "dict_values([tensor([[  101, 12773,  8472,  ...,     0,     0,     0],\n",
      "        [  101, 11053,  8172,  ...,     0,     0,     0],\n",
      "        [  101,   100,   100,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8663, 12997,  ...,     0,     0,     0],\n",
      "        [  101,  8363, 10996,  ...,     0,     0,     0],\n",
      "        [  101,  8975,   163,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1])])\n",
      "dict_values([tensor([[  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        [  101,  9573,  8372,  ...,     0,     0,     0],\n",
      "        [  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   153,   118,  ...,     0,     0,     0],\n",
      "        [  101,  8243, 12894,  ...,     0,     0,     0],\n",
      "        [  101,  8233,   112,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1])])\n",
      "dict_values([tensor([[  101,  8174,   159,  ...,     0,     0,     0],\n",
      "        [  101, 11338,   136,  ...,     0,     0,     0],\n",
      "        [  101, 10843,  8977,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8174,   166,  ...,     0,     0,     0],\n",
      "        [  101,  8174,  8541,  ...,     0,     0,     0],\n",
      "        [  101, 11086,  8383,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1])])\n",
      "dict_values([tensor([[  101,   143,  8363,  ...,     0,     0,     0],\n",
      "        [  101,  9100,  9947,  ...,     0,     0,     0],\n",
      "        [  101,  8174, 10076,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8513,   118,  ...,     0,     0,     0],\n",
      "        [  101, 10295,  8256,  ...,     0,     0,     0],\n",
      "        [  101, 11928, 11677,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0])])\n",
      "dict_values([tensor([[  101,   143, 12592,  ...,     0,     0,     0],\n",
      "        [  101, 10288,  8233,  ...,     0,     0,     0],\n",
      "        [  101,  9231,   112,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   143,   158,  ...,     0,     0,     0],\n",
      "        [  101,  9100, 10153,  ...,     0,     0,     0],\n",
      "        [  101,  8663,  8174,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0])])\n",
      "dict_values([tensor([[  101, 11643, 10369,  ...,     0,     0,     0],\n",
      "        [  101,   119,   119,  ...,     0,     0,     0],\n",
      "        [  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   119,   119,  ...,     0,     0,     0],\n",
      "        [  101, 10163, 11385,  ...,     0,     0,     0],\n",
      "        [  101,   113,   156,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1])])\n",
      "dict_values([tensor([[  101,   143,   161,  ...,     0,     0,     0],\n",
      "        [  101,  8330, 11099,  ...,     0,     0,     0],\n",
      "        [  101,  8174, 11149,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11311,  8936,  ...,     0,     0,     0],\n",
      "        [  101,  9721, 10800,  ...,     0,     0,     0],\n",
      "        [  101, 11136, 11325,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1])])\n",
      "dict_values([tensor([[  101,  8174, 12199,  ...,     0,     0,     0],\n",
      "        [  101,  8663,  9408,  ...,     0,     0,     0],\n",
      "        [  101,  9124,  8824,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8663,  9654,  ...,     0,     0,     0],\n",
      "        [  101,   143, 10512,  ...,     0,     0,     0],\n",
      "        [  101,   143, 10783,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1])])\n",
      "dict_values([tensor([[  101,  8243,  9886,  ...,     0,     0,     0],\n",
      "        [  101,   165,  8963,  ...,     0,     0,     0],\n",
      "        [  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        [  101, 11081,  9664,  ...,     0,     0,     0],\n",
      "        [  101,  8898,  9796,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0])])\n",
      "dict_values([tensor([[  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        [  101,  8174, 11149,  ...,     0,     0,     0],\n",
      "        [  101,  9510, 11531,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8243,  8983,  ...,     0,     0,     0],\n",
      "        [  101,  8233, 11325,  ...,     0,     0,     0],\n",
      "        [  101,  9064, 10917,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1])])\n",
      "dict_values([tensor([[  101,   143, 12785,  ...,     0,     0,     0],\n",
      "        [  101, 11927,  8118,  ...,     0,     0,     0],\n",
      "        [  101,  8174, 10859,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8174, 11149,  ...,     0,     0,     0],\n",
      "        [  101,   143,  8575,  ...,     0,     0,     0],\n",
      "        [  101, 11167, 11734,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0])])\n",
      "dict_values([tensor([[  101,  8792, 12667,  ...,     0,     0,     0],\n",
      "        [  101,  8174,  9341,  ...,     0,     0,     0],\n",
      "        [  101,  9266,  8788,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 12311,  8329,  ...,     0,     0,     0],\n",
      "        [  101,  8663, 12894,  ...,     0,     0,     0],\n",
      "        [  101, 11568,  8436,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1])])\n",
      "dict_values([tensor([[  101, 12713, 12825,  ...,     0,     0,     0],\n",
      "        [  101,  9941, 11385,  ...,     0,     0,     0],\n",
      "        [  101,   143, 11303,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        [  101,  9719,   117,  ...,     0,     0,     0],\n",
      "        [  101, 13048,  8205,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0])])\n",
      "dict_values([tensor([[  101, 10673,  8641,  ...,     0,     0,     0],\n",
      "        [  101, 11167,  9896,  ...,     0,     0,     0],\n",
      "        [  101,  8174, 12323,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   143,  8395,  ...,     0,     0,     0],\n",
      "        [  101,   143,  8120,  ...,     0,     0,     0],\n",
      "        [  101,  8233,   112,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1])])\n",
      "dict_values([tensor([[  101,   165,  8963,  ...,     0,     0,     0],\n",
      "        [  101,  9575,  8680,  ...,     0,     0,     0],\n",
      "        [  101,   145,  8326,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8554,  8310,  ...,     0,     0,     0],\n",
      "        [  101,  8233,  8658,  ...,     0,     0,     0],\n",
      "        [  101, 10310,  8753,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1])])\n",
      "dict_values([tensor([[  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        [  101,  8174, 10047,  ...,     0,     0,     0],\n",
      "        [  101,  9064,  8370,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   143, 11099,  ...,     0,     0,     0],\n",
      "        [  101,  8174,  9243,  ...,     0,     0,     0],\n",
      "        [  101,  8515,  8797,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])])\n",
      "dict_values([tensor([[  101, 10138,  9906,  ...,     0,     0,     0],\n",
      "        [  101, 10614,  8363,  ...,     0,     0,     0],\n",
      "        [  101,  8554,  8310,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 12773,  8154,  ...,     0,     0,     0],\n",
      "        [  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        [  101,  8233, 11325,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0])])\n",
      "dict_values([tensor([[  101,  8233, 11643,  ...,     0,     0,     0],\n",
      "        [  101,  8330, 11239,  ...,     0,     0,     0],\n",
      "        [  101,   143,  8988,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8174, 11344,  ...,     0,     0,     0],\n",
      "        [  101, 11136,   112,  ...,     0,     0,     0],\n",
      "        [  101,  8330,  9714,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0])])\n",
      "dict_values([tensor([[ 101, 9721, 9570,  ...,    0,    0,    0],\n",
      "        [ 101, 8670, 8174,  ...,    0,    0,    0],\n",
      "        [ 101, 8281, 8174,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 8429, 8205,  ...,    0,    0,    0],\n",
      "        [ 101, 9721, 9570,  ...,    0,    0,    0],\n",
      "        [ 101, 8898, 8174,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0])])\n",
      "dict_values([tensor([[  101,  8895,   156,  ...,     0,     0,     0],\n",
      "        [  101,  9064, 11759,  ...,     0,     0,     0],\n",
      "        [  101, 11515, 10903,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8451,  8436,  ...,     0,     0,     0],\n",
      "        [  101,   143,  8575,  ...,     0,     0,     0],\n",
      "        [  101,   113,  9796,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0])])\n",
      "dict_values([tensor([[  101, 10038,  8118,  ...,     0,     0,     0],\n",
      "        [  101,   162,  9570,  ...,     0,     0,     0],\n",
      "        [  101, 10125,  9059,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8898,  8880,  ...,     0,     0,     0],\n",
      "        [  101,  8554, 11099,  ...,     0,     0,     0],\n",
      "        [  101,   151,  8373,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0])])\n",
      "dict_values([tensor([[  101,   168, 11791,  ...,     0,     0,     0],\n",
      "        [  101,  8174,  8282,  ...,     0,     0,     0],\n",
      "        [  101, 11561,  8221,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11227,  8723,  ...,     0,     0,     0],\n",
      "        [  101,  9994,  8118,  ...,     0,     0,     0],\n",
      "        [  101, 10785,  8199,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1])])\n",
      "dict_values([tensor([[  101,  8757,  8204,  ...,     0,     0,     0],\n",
      "        [  101, 10560,  8354,  ...,     0,     0,     0],\n",
      "        [  101,  8993,  8357,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   153,  8277,  ...,     0,     0,     0],\n",
      "        [  101, 12605,  8220,  ...,     0,     0,     0],\n",
      "        [  101,  8233,  8310,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1])])\n",
      "dict_values([tensor([[  101,  9537, 10050,  ...,     0,     0,     0],\n",
      "        [  101,  8330,  8174,  ...,     0,     0,     0],\n",
      "        [  101,  8554,   148,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8174, 10091,  ...,     0,     0,     0],\n",
      "        [  101,  8422,  8541,  ...,     0,     0,     0],\n",
      "        [  101,  8217,  9172,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0])])\n",
      "dict_values([tensor([[  101,  9064, 10481,  ...,     0,     0,     0],\n",
      "        [  101,  8174, 10328,  ...,     0,     0,     0],\n",
      "        [  101,  8554,  8847,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   143,  8515,  ...,     0,     0,     0],\n",
      "        [  101,   143,  9982,  ...,     0,     0,     0],\n",
      "        [  101, 11055, 11207,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1])])\n",
      "dict_values([tensor([[  101,  8968, 11677,  ...,     0,     0,     0],\n",
      "        [  101,  9577,  8619,  ...,     0,     0,     0],\n",
      "        [  101,   143,  9353,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11685, 10289,  ...,     0,     0,     0],\n",
      "        [  101, 12513, 10448,  ...,     0,     0,     0],\n",
      "        [  101, 10380, 10537,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1])])\n",
      "dict_values([tensor([[  101,  8217,  8513,  ...,     0,     0,     0],\n",
      "        [  101,  8647,  9133,  ...,     0,     0,     0],\n",
      "        [  101,  8941,   147,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8275, 11515,  ...,     0,     0,     0],\n",
      "        [  101,  8384,  8891,  ...,     0,     0,     0],\n",
      "        [  101,  8554,  8310,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0])])\n",
      "dict_values([tensor([[  101,  8898,  8357,  ...,     0,     0,     0],\n",
      "        [  101,  8281,  8328,  ...,     0,     0,     0],\n",
      "        [  101,  8811,  9766,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 12311,  8329,  ...,     0,     0,     0],\n",
      "        [  101,  8174, 10153,  ...,     0,     0,     0],\n",
      "        [  101, 10088, 11630,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0])])\n",
      "dict_values([tensor([[  101,   143, 10353,  ...,     0,     0,     0],\n",
      "        [  101, 12311, 11041,  ...,     0,     0,     0],\n",
      "        [  101,  9510,  8895,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   143,   160,  ...,     0,     0,     0],\n",
      "        [  101,  8554,  8310,  ...,     0,     0,     0],\n",
      "        [  101,   165,  8778,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0])])\n",
      "dict_values([tensor([[  101,   165, 10143,  ...,     0,     0,     0],\n",
      "        [  101,   143,  8559,  ...,     0,     0,     0],\n",
      "        [  101, 11928,  8847,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8174,  8791,  ...,     0,     0,     0],\n",
      "        [  101,  8554,  8310,  ...,     0,     0,     0],\n",
      "        [  101,  8174,  9577,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0])])\n",
      "dict_values([tensor([[  101,  9735,  9537,  ...,     0,     0,     0],\n",
      "        [  101,  8422,  9193,  ...,     0,     0,     0],\n",
      "        [  101,   119,   119,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   143, 10782,  ...,     0,     0,     0],\n",
      "        [  101, 10564,  8916,  ...,     0,     0,     0],\n",
      "        [  101,  8429, 10037,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0])])\n",
      "dict_values([tensor([[  101,  8993,  9114,  ...,     0,     0,     0],\n",
      "        [  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        [  101,  8174, 11149,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  9059,  9064,  ...,     0,     0,     0],\n",
      "        [  101,   165,  8963,  ...,     0,     0,     0],\n",
      "        [  101,   143, 11149,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1])])\n",
      "dict_values([tensor([[  101,   143,  8134,  ...,     0,     0,     0],\n",
      "        [  101,  9064,  8217,  ...,     0,     0,     0],\n",
      "        [  101,   151,  8895,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8243,  8281,  ...,     0,     0,     0],\n",
      "        [  101,  8174, 13286,  ...,     0,     0,     0],\n",
      "        [  101,  8174, 11099,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1])])\n",
      "dict_values([tensor([[  101, 11785,  8362,  ...,     0,     0,     0],\n",
      "        [  101,  8975,  9552,  ...,     0,     0,     0],\n",
      "        [  101,  8174, 11149,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        [  101,   162,  9570,  ...,     0,     0,     0],\n",
      "        [  101,   143,  8282,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1])])\n",
      "dict_values([tensor([[  101,  8330,  8513,  ...,     0,     0,     0],\n",
      "        [  101,  8554, 11149,  ...,     0,     0,     0],\n",
      "        [  101,  8554, 11243,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   151,  9109,  ...,     0,     0,     0],\n",
      "        [  101,  8554, 11446,  ...,     0,     0,     0],\n",
      "        [  101,   143, 10843,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1])])\n",
      "dict_values([tensor([[  101,   143,  9716,  ...,     0,     0,     0],\n",
      "        [  101,   143,  8811,  ...,     0,     0,     0],\n",
      "        [  101,  8174, 10110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11330,  8171,  ...,     0,     0,     0],\n",
      "        [  101,   165, 10919,  ...,     0,     0,     0],\n",
      "        [  101,  8233,   112,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1])])\n",
      "dict_values([tensor([[  101,  8791,  9103,  ...,     0,     0,     0],\n",
      "        [  101, 10293,  9007,  ...,     0,     0,     0],\n",
      "        [  101,  8792,  9585,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11081,  9664,  ...,     0,     0,     0],\n",
      "        [  101,  9064,  8494,  ...,     0,     0,     0],\n",
      "        [  101,   119,   119,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1])])\n",
      "dict_values([tensor([[  101, 10163, 10168,  ...,     0,     0,     0],\n",
      "        [  101,   162, 10287,  ...,     0,     0,     0],\n",
      "        [  101, 13114,  8310,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 10016,  8914,  ...,     0,     0,     0],\n",
      "        [  101,  8233,   112,  ...,     0,     0,     0],\n",
      "        [  101,   165,  8963,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0])])\n",
      "dict_values([tensor([[  101, 10173,  8390,  ...,     0,     0,     0],\n",
      "        [  101, 10341, 10281,  ...,     0,     0,     0],\n",
      "        [  101,  8174, 12289,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   143, 11541,  ...,     0,     0,     0],\n",
      "        [  101,   119,   119,  ...,     0,     0,     0],\n",
      "        [  101,  9544,  8221,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 0, 1, 0, 0, 1])])\n"
     ]
    }
   ],
   "source": [
    "from fastNLP import prepare_torch_dataloader\n",
    "import torch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids, atten_mask, labels = [], [], []\n",
    "    max_length = [0] * 3\n",
    "\n",
    "    for each_item in batch:\n",
    "        input_ids.append(each_item[\"input_ids\"].tolist())\n",
    "        max_length[0] = max(max_length[0], len(each_item[\"input_ids\"].tolist()))\n",
    "        atten_mask.append(each_item[\"attention_mask\"].tolist())\n",
    "        max_length[1] = max(max_length[1], len(each_item[\"attention_mask\"].tolist()))\n",
    "\n",
    "        labels.append([each_item[\"label\"]])\n",
    "        max_length[2] = max(max_length[2], len([each_item[\"label\"]]))\n",
    "\n",
    "    for i in range(3):\n",
    "        each = (input_ids, atten_mask, labels)[i]\n",
    "        for item in each:\n",
    "            item.extend([0] * (max_length[i] - len(item)))\n",
    "\n",
    "    return {'input_ids': torch.cat([torch.tensor([item]) for item in input_ids], dim=0),\n",
    "            'attention_mask': torch.cat([torch.tensor([item]) for item in atten_mask], dim=0),\n",
    "            'labels': torch.cat([torch.tensor(item) for item in labels], dim=0)}\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "&emsp;&emsp;最后使用 `prepare_torch_dataloader` 来加载数据，对 `tokenizer` 处理过的训练集数据、验证集数据，进行预处理和批量划分："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = data_bundle.get_dataset('train')\n",
    "evaluate_dataset = data_bundle.get_dataset('val')\n",
    "train_dataloader = prepare_torch_dataloader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "evaluate_dataloader = prepare_torch_dataloader(evaluate_dataset, batch_size=16, collate_fn=collate_fn)\n",
    "for i in evaluate_dataloader:\n",
    "    print(i.values())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. 模型训练：加载 StructBERT、fastNLP 参数匹配、fine-tuning\n",
    "\n",
    "&emsp;&emsp;最后就是模型训练的不分，需要使用 `damo/nlp_structbert_sentiment-classification_chinese-base` 搭建分类模型，此处使用的 `nn.Module` 模块搭建模型，与 `tokenizer` 类似，通过从 `modelscope` 库中导入 `SbertModel` 模块，加载模型，并且导入 `SbertConfig` 模块，加载模型配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 17:02:09,574 - modelscope - INFO - initialize model from /remote-home/kychen/.cache/modelscope/hub/damo/nlp_structbert_sentiment-classification_chinese-base\n",
      "2022-11-10 17:02:15,055 - modelscope - INFO - All model checkpoint weights were used when initializing SequenceClassificationModel.\n",
      "\n",
      "2022-11-10 17:02:15,057 - modelscope - INFO - All the weights of SequenceClassificationModel were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use SequenceClassificationModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from modelscope.models.nlp import SbertModel\n",
    "from modelscope.models.nlp.structbert import SbertConfig\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class SeqClsModel(nn.Module):\n",
    "    def __init__(self, num_labels, model_checkpoint):\n",
    "        nn.Module.__init__(self)\n",
    "        self.num_labels = num_labels\n",
    "        self.config = SbertConfig.from_pretrained(model_checkpoint)\n",
    "\n",
    "        self.back_bone = SbertModel.from_pretrained(model_checkpoint, config=self.config,num_labels=num_labels)\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.back_bone(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def train_step(self, input_ids, attention_mask, labels):\n",
    "        loss = self(input_ids, attention_mask, labels)[\"loss\"]\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def evaluate_step(self, input_ids, attention_mask, labels):\n",
    "\n",
    "        pred = self(input_ids, attention_mask, labels)[\"logits\"]\n",
    "        pred = torch.max(pred, dim=-1)[1]\n",
    "        return {'pred': pred, 'target': labels}\n",
    "\n",
    "\n",
    "model = SeqClsModel(num_labels=2, model_checkpoint=model_checkpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "&emsp;&emsp;初始化优化器 `Optimizer`、训练模块 `Trainer`，最后，使用之前完成的 `train_dataloader` 和 `evaluate_dataloader`，训练模块 `Trainer`，得到训练结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[17:03:43] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running evaluator sanity check for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> batches.              <a href=\"file:///remote-home/kychen/anaconda3/envs/pytorch/lib/python3.8/site-packages/fastNLP/core/controllers/trainer.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/kychen/anaconda3/envs/pytorch/lib/python3.8/site-packages/fastNLP/core/controllers/trainer.py#661\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">661</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[17:03:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running evaluator sanity check for \u001b[1;36m2\u001b[0m batches.              \u001b]8;id=288091;file:///remote-home/kychen/anaconda3/envs/pytorch/lib/python3.8/site-packages/fastNLP/core/controllers/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=487404;file:///remote-home/kychen/anaconda3/envs/pytorch/lib/python3.8/site-packages/fastNLP/core/controllers/trainer.py#661\u001b\\\u001b[2m661\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49456f0b6d614ed186e6cbd3d9c31a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/remote-home/kychen/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/modeling_\n",
       "utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of\n",
       "Transformers.\n",
       "  warnings.warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/remote-home/kychen/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/modeling_\n",
       "utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of\n",
       "Transformers.\n",
       "  warnings.warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a49d012f3f404f8d30a359555263fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------- Eval. results on Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> -----------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------- Eval. results on Epoch:\u001b[1;36m1\u001b[0m, Batch:\u001b[1;36m0\u001b[0m -----------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"acc#acc\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7375</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"acc#acc\"\u001b[0m: \u001b[1;36m0.7375\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------- Eval. results on Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> -----------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------- Eval. results on Epoch:\u001b[1;36m2\u001b[0m, Batch:\u001b[1;36m0\u001b[0m -----------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"acc#acc\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.76875</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"acc#acc\"\u001b[0m: \u001b[1;36m0.76875\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------- Eval. results on Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> -----------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------- Eval. results on Epoch:\u001b[1;36m3\u001b[0m, Batch:\u001b[1;36m0\u001b[0m -----------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"acc#acc\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.76875</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"acc#acc\"\u001b[0m: \u001b[1;36m0.76875\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------- Eval. results on Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> -----------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------- Eval. results on Epoch:\u001b[1;36m4\u001b[0m, Batch:\u001b[1;36m0\u001b[0m -----------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"acc#acc\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.75625</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"acc#acc\"\u001b[0m: \u001b[1;36m0.75625\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------- Eval. results on Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> -----------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------- Eval. results on Epoch:\u001b[1;36m5\u001b[0m, Batch:\u001b[1;36m0\u001b[0m -----------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"acc#acc\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.775</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"acc#acc\"\u001b[0m: \u001b[1;36m0.775\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------- Eval. results on Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> -----------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------- Eval. results on Epoch:\u001b[1;36m6\u001b[0m, Batch:\u001b[1;36m0\u001b[0m -----------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"acc#acc\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.775</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"acc#acc\"\u001b[0m: \u001b[1;36m0.775\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------- Eval. results on Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> -----------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------- Eval. results on Epoch:\u001b[1;36m7\u001b[0m, Batch:\u001b[1;36m0\u001b[0m -----------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"acc#acc\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"acc#acc\"\u001b[0m: \u001b[1;36m0.8\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------- Eval. results on Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> -----------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------- Eval. results on Epoch:\u001b[1;36m8\u001b[0m, Batch:\u001b[1;36m0\u001b[0m -----------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"acc#acc\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.74375</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"acc#acc\"\u001b[0m: \u001b[1;36m0.74375\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------- Eval. results on Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> -----------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------- Eval. results on Epoch:\u001b[1;36m9\u001b[0m, Batch:\u001b[1;36m0\u001b[0m -----------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"acc#acc\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7375</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"acc#acc\"\u001b[0m: \u001b[1;36m0.7375\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">---------------------------- Eval. results on Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> -----------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "---------------------------- Eval. results on Epoch:\u001b[1;36m10\u001b[0m, Batch:\u001b[1;36m0\u001b[0m -----------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"acc#acc\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"acc#acc\"\u001b[0m: \u001b[1;36m0.8\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastNLP import Trainer, Accuracy\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizers = AdamW(params=model.parameters(), lr=5e-5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    driver='torch',\n",
    "    device=1,  # 'cuda'\n",
    "    n_epochs=10,\n",
    "    optimizers=optimizers,\n",
    "    train_dataloader=train_dataloader,\n",
    "    evaluate_dataloaders=evaluate_dataloader,\n",
    "    metrics={'acc': Accuracy()}\n",
    ")\n",
    "\n",
    "trainer.run(num_eval_batch_per_dl=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c8c34564754933bf24f768d86f48e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'acc#acc': 0.802752}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluator.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fnlp-torch-1.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e975e1f9360e1921e74d0e93bce624cf2bd4e5b37f41126c7b40eae17538fdd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
